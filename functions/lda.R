
#' Train an LDA model using Mallet.
#'
#' @param documents A data frame with two attributes
#'         $id: the ids for the documents
#'        $text: the raw text of the document
#' @param num.topics The number of topis to be trained.
#' @param stoplist A path to the stopword list to use
#' @param token.regexp A regular expression for splitting the text into tokens
#'
#' @return The trianed topic model as a list. This
#'   documents: the documents used to train this topic model
#'   vocabulary: A vector of all tokens found in the supplied documents (after any
#'         transformations). Note that the order of this vector matters since the
#'         The vocabulary is the starting point for identify the various words in
#'         topic vectors and other structures.
#'   wordFreq: Word frequency counts for each term in the vocabulary. This is a
#'         data frame in which each row containes the index of the token, the observed
#'         token (stemmed, if stemming is performed), the total number of times the
#'         token appears and the number of documents in which the token appears
#'   model: The trained topic model.
#'   topics: The matrix of topics as a K x N matrix where K is the number of topics
#'         and N is the number of words in the corpus. Each row corresponds to a topic,
#'         while each column contains the likelihood that a particular word will be
#'         generated by this model. Word order is given by the vocabulary vector.
#'   docAssigments: The topic porportions for each document. A matrix with D rows and K
#'         columns.
#'   K: The number of topics for this model
#'   N: The number of terms in the vocabulary of this model
#'   D: The number of documents used to train this model
trainSimpleLDAModel <- function(documents,
                                num.topics,
                                stoplist = "data/stoplist.csv",
                                token.regexp="\\p{L}[\\p{L}\\p{P}]+\\p{L}")
{
  mallet.instances <- mallet.import(unlist(documents$id),
                                    unlist(documents$text),
                                    stoplist,
                                    FALSE,
                                    token.regexp=token.regexp)
  topic.model <- MalletLDA(num.topics=num.topics)
  topic.model$loadDocuments(mallet.instances)
  vocabulary <- topic.model$getVocabulary()
  word.freqs <- mallet.word.freqs(topic.model)
  #topic.model$setAlphaOptimization(40, 80)
  topic.model$train(1000)

  # construct result
  result <- list()
  result$model <- topic.model
  result$documents <- documents
  result$vocabulary <- vocabulary
  result$wordFreq <- word.freqs

  result$topics <- mallet.topic.words(topic.model, smoothed=TRUE, normalized=TRUE)
  colnames(result$topics) <- vocabulary
  result$docAssignments <- mallet.doc.topics(topic.model, normalized=T, smoothed=F)

  result$K <- nrow(result$topics)
  result$N <- ncol(result$topics)
  result$D <- nrow(result$documents)

  return(result)
}

getTopic <- function(lda.model, k)
{
  getWords <- function()
  {
    terms <- model$topic[2, ]
    terms <- terms[order(terms, decreasing=T)]
  }
  
  topic <- list()
  topic$model <- lda.model
  topic$k <- k
  topic$getWords <- getWords
  return (topic)
}

plotTopicWc <- function(lda.model, k, K, output="plots", prefix="Topic-", num.words=100, verbose=T)
{
    K <- lda.model$K
    topic.top.words <- mallet.top.words(lda.model$model, lda.model$topics[k, ], num.words)
    plot.fname <- paste(output, "/", prefix, k, ".png", sep="")
    if (verbose)
      print(paste("Generating wordcloud for topic ", k, "of", K, ":", plot.fname))

    png(plot.fname, width=12, height=8, units="in", res=300)
    wordcloud(topic.top.words$words,
              topic.top.words$weights,
              scale=c(4, .2),
              rot.per=0.1,
              random.order=FALSE,
              colors=brewer.pal(8, "Dark2"))
    dev.off()
}

plotTopicWordcloud <- function(lda.model, output="plots", prefix="Topic-", num.words=100, verbose=T)
{
#   pal <- brewer.pal(9,"BuGn")
#   pal <- pal[-(1:4)]
#   topic.words.m <- mallet.topic.words(lda.model$model, smoothed=TRUE, normalized=TRUE)
#   colnames(topic.words.m) <- lda.model$vocabulary
  if (verbose)
    print(paste("Generating wordclouds for", lda.model$K, "topics."))

  for (topic.ix in 1:lda.model$K)
  {
    plot.fname <- paste(output, "/", prefix, topic.ix, ".png", sep="")
    if (verbose)
      print(paste("Generating wordcloud for topic ", topic.ix, "of", lda.model$K, ":", plot.fname))

    png(plot.fname, width=12, height=8, units="in", res=300)
    topic.top.words <- mallet.top.words(lda.model$model, lda.model$topics[topic.ix, ], num.words)
    wordcloud(topic.top.words$words,
              topic.top.words$weights,
              scale=c(4, .2),
              rot.per=0.1,
              random.order=FALSE,
              colors=brewer.pal(8, "Dark2"))
    dev.off()
  }

  if (verbose)
    print("Finished generating wordclouds.");
}
